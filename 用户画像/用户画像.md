# 用户画像简介

## 定位与应用

- 定位：用户画像是一种数据服务

- 应用：

  - 运营决策  

    了解用户群体，聚焦目标用户，定位产品方向。

  - 精准营销 

    营销活动推送、广告投放、个性化推荐。

  - 分群洞察

    寻找高价值用户，挽留待流失用户，提升用户活跃。

![](img/03.png)



## 架构

![](img/04.png)



## 项目教学模块

（1）理解用户画像系统的设计思路，以及标签的设计流程与应用。

（2）用户画像管理平台的搭建及使用。

（3）掌握用户画像平台的数据库表，包括标签表、任务表、进度表等全部表含义。

（4）使用spark开发标签计算、重组、导出等操作，完成标签计算的业务处理流程。 

（5）利用clickhouse\Redis实现对画像数据的存储及多个标签的组合筛选。

（6）学习用Springboot、Mybatis等框架，完成用户分群功能。

（7）入门机器学习，用sparkmllib中的算法完成挖掘类标签的开发。





# 批处理任务开发

## 任务一：统计型和规则型标签的SQL处理

### 总体处理流程

目前虽然填写了一个标签任务，但是并不是光靠一个SQL就能生成标签的，还要结合任务定义中的其他规则来计算标签数据。

那么这个 “定义+规则+SQL=标签” 这个步骤需要一个spark程序Jar包来完成，并且存储在HDFS。

系统在每日的凌晨0点或者手动会把对应的标签任务生成为待执行的任务进程。

达到任务进程的要求时（1 任务执行时点、2任务执行层级），会推送JSON格式的作业提交信息传给远端的任务提交器。

任务提交器会根据JSON组合生成spark-submit及相关参数，提交YARN。

YARN会根据提交时的JAR包路径生成Spark作业。

Spark作业执行阶段会读取MySQL库中标签定义、规则和SQL，去查询Hive中的数据通过计算生成标签最后写入画像库的某张标签表。

在Spark作业提交后，远程提交器会一直监控该作业的运行状态并通过回调，传递给用户画像管理平台，用于监控。

![](img/01.png)



**远端任务提交器**：

获取方式一：本课程提供的（尚硅谷自研）

获取方式二：开源组件  https://livy.incubator.apache.org/



### 任务目标

完成Spark作业执行的JAR包。

读取标签定义及规则，组合成SQL，在数仓中执行，并写入画像标签库。



### 任务步骤

（1）查询任务信息

（2）查询标签信息

（3）查询子标签对应规则

（4）生成标签表（如果不存在）

（5）组合写入标签SQL

（6）执行SQL



### maven 依赖范围

> 视频坐标：p21，24min

- compile：主程序和测试程序都能用，参与打包
- test：测试程序能用，不参与打包
- provided：主程序和测试程序能用，只在编译期有效，不参与打包





## 任务二：标签的宽表合并

### 任务目标

当所有的单独标签任务都计算完成时，为了更加方便的查询及导出数据，要拼接出一张以用户ID为主键的宽表。宽表的每一列用三级标签编号作为列名。

这张大宽表，包含了所有的标签，有多少个标签，就会有多少列。



### 任务步骤

（1）读取所有启动的标签任务中的标签列表

（2）读取标签列表中的标签编码和标签值类型，获得字段名和字段值，拼接成建表语句

（3）根据标签列表组合多表合并，同时进行行转列，组合成insert select 语句。



### 将多个表合并成一个宽表

方式 1：join

方式 2：union  -->  group by  -->  sum if

方式 3：pivot  【spark-sql 特有关键词】



### 关于 pivot 

把整个表整理成3种列：维度列、旋转列、聚合列

1）格式

```sql
select * 
from tablename pivot ( sum(聚合列) as 列标识  for 旋转列 in( 旋转列值1 ,旋转列值2,旋转列值3) ) 
```

2）旋转列

原来是某个列的行值，现在要从行值要转为列的字段

3）聚合列

对于旋转后的新列，要聚合的值

4）除了旋转列和聚合列，默认都是维度列，如果存在这三种以外的字段，需要提前用子查询去除





## 任务三：数据迁移至Clickhouse

### 为何要迁移

标签计算完成后保存在hive虽然可以查询但是性能非常糟糕。而标签的使用往往是即时的。最常见的场景就是“用户分群”，也称“人群圈选”、“圈人”。

分群操作就是根据多个标签组合，产生一个用户集合，供营销、广告等部门使用。而这些操作计算量大，产生结果需要时效性高。



### 任务目标

 把hive中标签宽表数据，写入至Clickhouse的宽表。



### 任务步骤

（1）在clickhouse中建立对应的宽表。

（2）因为并不是hive表到hive表，所以 并不能够直接用 insert select 解决

需要先通过把数据查询成为Dataframe，再通过行动算子写入至Clickhouse的宽表。



### 幂等

去重  ==> 幂等  ==> 一般是实时处理中

离线计算中如果要考虑幂等，一般是选择将上次计算失败的残留数据直接清空。





## 任务四：在Clickhouse中将宽表转换为Bitmap表

### 为什么用Bitmap

存储成本低：如果有一个超大的无序且不重复的整数集合，用Bitmap的存储成本是非常低的。

天然去重：因为每个值都只对应唯一的一个位置，不能存储两个值，所以Bitmap结构可以天然去重。

快速定位：非常方便快速的查询某个元素是否在集合中。

集合间计算：计算机做与、或、非、异或 等操作是非常快的。

**优势场景**

（1）海量数据的压缩存储

（2）去重存储

（3）判断值存在于集合

（4）集合之间的交并差

**局限性**

（1）只能存储正整数而不是字符串

（2）存储的值必须是无序不重复

（3）不适合存储稀疏的集合，但是clickhouse使用的RoaringBitmap，优化了这个稀疏问题。



### 任务目标

为了能够更快的进行条件查询群体，把clickhouse中的宽表，通过行转列、聚合等操作转入Bitmap表。



### 任务步骤

（1）读取标签定义表，用于获得标签名称和标签值类型。

（2）建立四种不同数据类型的标签值表。

（3）根据标签值类型的不同要写入到四种不同的Bitmap表中。



### 转换过程

![](img/02.png)





# 即席分群开发

## 五个功能 

1 将分群信息保存到Mysql中

2 在Clickhouse中生成人群包

3 将Clickhouse中生成的人群包转储到Redis中

4 预估人数

5 更新分群